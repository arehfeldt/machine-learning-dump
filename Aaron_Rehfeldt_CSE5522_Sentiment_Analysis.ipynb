{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arehfeldt/machine-learning-dump/blob/main/Aaron_Rehfeldt_CSE5522_Sentiment_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTPwb8ny-hOU"
      },
      "source": [
        "**CSE 5522 Lab #2: Sentiment Analysis**\n",
        "\n",
        "The goals of this lab are to familarize you with:\n",
        "\n",
        "*   Naive Bayes\n",
        "*   Binary Classification\n",
        "*   Data exploration\n",
        "*   Working with text-based data (Tweets)\n",
        "\n",
        "**Initial notes**\n",
        "\n",
        "* (If you are using Google Colab) Make a copy of this page in your google drive so that you can edit it.\n",
        "\n",
        "* While not completely necessary for this assignment, you may want to familiarize yourself with the following packages: [numpy](https://numpy.org), [scikit-learn](https://scikit-learn.org), [pandas](https://pandas.pydata.org), [matplotlib](https://matplotlib.org).\n",
        " * Especially numpy, many of the calculations in this (and later) lab can be done in one line using numpy. Whereas raw python may require 5-10x that.\n",
        "\n",
        "* Feel free to (please do!) change the structure of the document below. Especially, add code sections to break your code into logical pieces and add text sections to explain your code or results\n",
        "\n",
        "---\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sp2T5S8IQTct"
      },
      "source": [
        "**Part 1: Hands-On #2 (0 pts)**\n",
        "\n",
        "You will need to finish any remaining parts of the Hands-On that you didn't finish in class. Feel free to use code from the posted Hands-On #2 (partial) solution.\n",
        "\n",
        "Note, you do not need to explicitly include the your Hands-On #2 solution here. But parts 2 and 3 assume you have a working solution, and you will probably need/want to copy code from it when you work on them."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4o91af4eorPS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa100bd5-8f56-4584-c4f0-7a2d5380690b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TweetUrl='https://github.com/aasiaeet/cse5522data/raw/master/db3_final_clean.csv'\n",
        "tweet_dataframe=pd.read_csv(TweetUrl)\n",
        "\n",
        "# wordDict maps words to id\n",
        "# X is the document-word matrix holding the presence/absence of words in each tweet\n",
        "wordDict = {}\n",
        "idCounter = 0\n",
        "for i in range(tweet_dataframe.shape[0]):\n",
        "  allWords = tweet_dataframe.iloc[i,1].split(\" \")\n",
        "  for word in allWords:\n",
        "    if word not in wordDict:\n",
        "      wordDict[word] = idCounter\n",
        "      idCounter += 1\n",
        "\n",
        "# initialize x and y\n",
        "X = np.zeros((tweet_dataframe.shape[0], idCounter),dtype='float')\n",
        "y = np.array(tweet_dataframe.iloc[:,2])\n",
        "\n",
        "# fill in x by placing 1's corresponding to the presence of a word for each tweet\n",
        "for i in range(tweet_dataframe.shape[0]):\n",
        "  allWords = tweet_dataframe.iloc[i,1].split(\" \")\n",
        "  for word in allWords:\n",
        "    X[i, wordDict[word]]  = 1\n",
        "\n",
        "print (X.shape, np.max(np.sum(X, axis=1)))\n",
        "\n",
        "# compute_distrobutions:\n",
        "#   x - test data features\n",
        "#   y - true label of test data\n",
        "#   returns the probability of a word being present in a tweet given that the tweet was positive/negative about the weather\n",
        "def compute_distrobutions(x, y):\n",
        "  # computes the probability of a word being present in a tweet given that the tweet was positive/negative about the weather\n",
        "  probWordGivenPositive = sum(x[y > 0]) / sum(y > 0)\n",
        "  probWordGivenNegative = sum(x[y < 0]) / sum(y < 0)\n",
        "\n",
        "  # computes the prior probability of a tweet being positive or negative\n",
        "  priorPositive = sum(y > 0) / y.size\n",
        "  priorNegative = sum(y < 0) / y.size\n",
        "\n",
        "  return probWordGivenPositive, probWordGivenNegative, priorPositive, priorNegative\n",
        "\n",
        "def compute_log_probabilities(probability, minimum_probability):\\\n",
        "  # take care of 0 counts in our probability\n",
        "  probability=np.where(probability>=minimum_probability,probability,minimum_probability)\n",
        "  probability=np.where(probability<=(1-minimum_probability),probability,1-minimum_probability)\n",
        "\n",
        "  return np.log(probability), np.log(1-probability)\n",
        "\n",
        "\n",
        "# classifyNB:\n",
        "#   words - vector of words of the tweet (binary vector)\n",
        "#   logProbWordPresentGivenPositive - log P(x_j = 1|+)\n",
        "#   logProbWordAbsentGivenPositive  - log P(x_j = 0|+)\n",
        "#   logProbWordPresentGivenNegative - log P(x_j = 1|-)\n",
        "#   logProbWordAbsentGivenNegative  - log P(x_j = 0|-)\n",
        "#   logPriorPositive - log P(+)\n",
        "#   logPriorNegative - log P(-)\n",
        "#   returns (label of x according to the NB classification rule, confidence about the label)\n",
        "\n",
        "# Note: you can also change the function definition if you wish to encapsulate all six log probs\n",
        "# as one model; just make sure to follow through below\n",
        "\n",
        "def classifyNB(words,logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive,\n",
        "               logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative,\n",
        "               logPriorPositive, logPriorNegative):\n",
        "\n",
        "  probTweetPositive = np.exp(logPriorPositive + np.sum(logProbWordPresentGivenPositive[words==1]) + np.sum(logProbWordAbsentGivenPositive[words==0]))\n",
        "  probTweetNegative = np.exp(logPriorNegative + np.sum(logProbWordPresentGivenNegative[words==1]) + np.sum(logProbWordAbsentGivenNegative[words==0]))\n",
        "\n",
        "  if probTweetPositive > probTweetNegative:\n",
        "    return 1, np.log(probTweetPositive / probTweetNegative)\n",
        "  else:\n",
        "    return -1, np.log(probTweetNegative / probTweetPositive)\n",
        "\n",
        "\n",
        "# testNB: Classify all xTest\n",
        "#   xTest - test data features\n",
        "#   yTest - true label of test data\n",
        "#   logProbWordPresentGivenPositive - log P(x_j = 1|+)\n",
        "#   logProbWordAbsentGivenPositive  - log P(x_j = 0|+)\n",
        "#   logProbWordPresentGivenNegative - log P(x_j = 1|-)\n",
        "#   logProbWordAbsentGivenNegative  - log P(x_j = 0|-)\n",
        "#   logPriorPositive - log P(+)\n",
        "#   logPriorNegative - log P(-)\n",
        "#   returns Average test error\n",
        "def testNB(xTest, yTest,\n",
        "           logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative,\n",
        "           logPriorPositive, logPriorNegative):\n",
        "  totalError = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  numPos = 0\n",
        "  numNeg = 0\n",
        "\n",
        "  for i, words in enumerate(xTest):\n",
        "    classification, confidence = classifyNB(words,logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive,\n",
        "               logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative,\n",
        "               logPriorPositive, logPriorNegative)\n",
        "\n",
        "    if classification != yTest[i]: totalError = totalError + 1\n",
        "    if classification == 1:\n",
        "      posConfidence += confidence\n",
        "      numPos += 1\n",
        "    else:\n",
        "      negConfidence += confidence\n",
        "      numNeg += 1\n",
        "\n",
        "  # compute accuracy and confidence\n",
        "  avgPosConfidence = posConfidence / numPos\n",
        "  avgNegConfidence = negConfidence / numNeg\n",
        "  accuracy = 1 - totalError/yTest.size\n",
        "  return accuracy, avgPosConfidence, avgNegConfidence\n",
        "\n",
        "# NtestNB: Run N iterations of testNB and gather average accuracy and confidence\n",
        "#   n - number of iterations\n",
        "#   X - occurance of words\n",
        "#   y - lables of data\n",
        "#   returns Average accuracy and confidence on positive and negative guesses for testNB over N iterations\n",
        "\n",
        "def NTestNB(n, X, y):\n",
        "  accuracy = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  for i in range(n):\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2)\n",
        "    # gets the prior probabilities and conditional probabilities from our training data\n",
        "    probWordGivenPositive, probWordGivenNegative, priorPositive, priorNegative = compute_distrobutions(xTrain,yTrain)\n",
        "    # converts probabilities to log form\n",
        "    min_prob = 1/yTrain.shape[0]\n",
        "    logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive = compute_log_probabilities(probWordGivenPositive, min_prob)\n",
        "    logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative = compute_log_probabilities(probWordGivenNegative, min_prob)\n",
        "    logPriorPositive, logPriorNegative = compute_log_probabilities(priorPositive, min_prob)\n",
        "\n",
        "    # performs test and sums accuracy/confidence\n",
        "    testAccuracy, testPosConfidence, testNegConfidence = testNB(xTest, yTest,\n",
        "           logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative,\n",
        "           logPriorPositive, logPriorNegative)\n",
        "\n",
        "    accuracy += testAccuracy\n",
        "    posConfidence += testPosConfidence\n",
        "    negConfidence += testNegConfidence\n",
        "\n",
        "  avgAccuracy = accuracy / n\n",
        "  avgPosConfidence = posConfidence / n\n",
        "  avgNegConfidence = negConfidence / n\n",
        "  # print results of N tests\n",
        "  print(\"--------------------NB--------------------\")\n",
        "  print(f\"Over {n} tests our NB was {avgAccuracy * 100}% accuracy on average\")\n",
        "  print(f\"Over {n} tests our NB scored {avgPosConfidence} confidence on positive guesses\")\n",
        "  print(f\"Over {n} tests our NB scored {avgNegConfidence} confidence on negative guesses\")\n",
        "\n",
        "  return avgAccuracy, avgPosConfidence, avgNegConfidence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3697, 5989) 29.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VChu9SYOPQ6G"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "**Part 2: An Alternate Model (50 pts)**\n",
        "\n",
        "In Part 1, you calculated the probability of a tweet by incorporating both the probability of words present in the tweet $P\\left(x^i_j=1 | +\\right)$ and the probability of words absent from the tweet $P\\left(x^i_j=0 | +\\right)$.\n",
        "\n",
        "Now, modify your code to *only* incorporate the probability of words present in the tweet $P\\left(x^i_j=1 | +\\right)$ (thus ignoring absent words).\n",
        "\n",
        "Compare this to the original approach in Part 1. Follow reasonable experimental procedure and write up an explanation of the results you find.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aK9cc3aFpBi4"
      },
      "source": [
        "# classifyNBOnlyPresent:\n",
        "#   words - vector of words of the tweet (binary vector)\n",
        "#   logProbWordPresentGivenPositive - log P(x_j = 1|+)\n",
        "#   logProbWordPresentGivenNegative - log P(x_j = 1|-)\n",
        "#   logPriorPositive - log P(+)\n",
        "#   logPriorNegative - log P(-)\n",
        "#   returns (label of x according to the NB classification rule, confidence about the label)\n",
        "\n",
        "# Note: you can also change the function definition if you wish to encapsulate all six log probs\n",
        "# as one model; just make sure to follow through below\n",
        "\n",
        "def classifyNBOnlyPresent(words,logProbWordPresentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logPriorPositive, logPriorNegative):\n",
        "\n",
        "  probTweetPositive = np.exp(logPriorPositive + np.sum(logProbWordPresentGivenPositive[words==1]))\n",
        "  probTweetNegative = np.exp(logPriorNegative + np.sum(logProbWordPresentGivenNegative[words==1]))\n",
        "\n",
        "  if probTweetPositive > probTweetNegative:\n",
        "    return 1, np.log(probTweetPositive / probTweetNegative)\n",
        "  else:\n",
        "    return -1, np.log(probTweetNegative / probTweetPositive)\n",
        "\n",
        "\n",
        "# testNBOnlyPresent: Classify all xTest\n",
        "#   xTest - test data features\n",
        "#   yTest - true label of test data\n",
        "#   logProbWordPresentGivenPositive - log P(x_j = 1|+)\n",
        "#   logProbWordAbsentGivenPositive  - log P(x_j = 0|+)\n",
        "#   logPriorPositive - log P(+)\n",
        "#   logPriorNegative - log P(-)\n",
        "#   returns Average test error\n",
        "def testNBOnlyPresent(xTest, yTest, logProbWordPresentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logPriorPositive, logPriorNegative):\n",
        "  totalError = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  numPos = 0\n",
        "  numNeg = 0\n",
        "\n",
        "  for i, words in enumerate(xTest):\n",
        "    classification, confidence = classifyNBOnlyPresent(words,logProbWordPresentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logPriorPositive, logPriorNegative)\n",
        "\n",
        "    if classification != yTest[i]: totalError = totalError + 1\n",
        "    if classification == 1:\n",
        "      posConfidence += confidence\n",
        "      numPos += 1\n",
        "    else:\n",
        "      negConfidence += confidence\n",
        "      numNeg += 1\n",
        "\n",
        "  # compute accuracy and confidence\n",
        "  avgPosConfidence = posConfidence / numPos\n",
        "  avgNegConfidence = negConfidence / numNeg\n",
        "  accuracy = 1 - totalError/yTest.size\n",
        "  return accuracy, avgPosConfidence, avgNegConfidence\n",
        "\n",
        "# NtestNBOnlyPresent: Run N iterations of testNB and gather average accuracy and confidence\n",
        "#   n - number of iterations\n",
        "#   X - occurance of words\n",
        "#   y - lables of data\n",
        "#   returns Average accuracy and confidence on positive and negative guesses for testNBOnlyPresent over N iterations\n",
        "\n",
        "def NTestNBOnlyPresent(n, X, y):\n",
        "  accuracy = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  for i in range(n):\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2)\n",
        "    # gets the prior probabilities and conditional probabilities from our training data\n",
        "    probWordGivenPositive, probWordGivenNegative, priorPositive, priorNegative = compute_distrobutions(xTrain,yTrain)\n",
        "    # converts probabilities to log form\n",
        "    min_prob = 1/yTrain.shape[0]\n",
        "    logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive = compute_log_probabilities(probWordGivenPositive, min_prob)\n",
        "    logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative = compute_log_probabilities(probWordGivenNegative, min_prob)\n",
        "    logPriorPositive, logPriorNegative = compute_log_probabilities(priorPositive, min_prob)\n",
        "\n",
        "    # performs test and sums accuracy/confidence\n",
        "    testAccuracy, testPosConfidence, testNegConfidence = testNBOnlyPresent(xTest, yTest,\n",
        "           logProbWordPresentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logPriorPositive, logPriorNegative)\n",
        "\n",
        "    accuracy += testAccuracy\n",
        "    posConfidence += testPosConfidence\n",
        "    negConfidence += testNegConfidence\n",
        "\n",
        "  avgAccuracy = accuracy / n\n",
        "  avgPosConfidence = posConfidence / n\n",
        "  avgNegConfidence = negConfidence / n\n",
        "  # print results of N tests\n",
        "  print(\"--------------------NBOnlyPresent--------------------\")\n",
        "  print(f\"Over {n} tests our NB was {avgAccuracy * 100}% accuracy on average\")\n",
        "  print(f\"Over {n} tests our NB scored {avgPosConfidence} confidence on positive guesses\")\n",
        "  print(f\"Over {n} tests our NB scored {avgNegConfidence} confidence on negative guesses\")\n",
        "  return avgAccuracy, avgPosConfidence, avgNegConfidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbVQjVugPZ7E"
      },
      "source": [
        "## Part 2.B: Testing Only Absent\n",
        "\n",
        "After seeing very little difference between Part 1 and Part 2 in our accuracy and confidence, I wanted to see if testing with only the absense of words would help shed some light on what was happening.\n",
        "\n",
        "My hypothesis is that the presense of a word far outweighs the absense of a word, synonyms mean that 1 word could be very similar contextually to 10 or more words in our word bag. So if we only use absenses we should see far less accuracy and confidence.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpkDTHhJQLBJ"
      },
      "source": [
        "# classifyNBOnlyAbsent:\n",
        "#   words - vector of words of the tweet (binary vector)\n",
        "#   logProbWordAbsentGivenPositive  - log P(x_j = 0|+)\n",
        "#   logProbWordAbsentGivenNegative  - log P(x_j = 0|-)\n",
        "#   logPriorPositive - log P(+)\n",
        "#   logPriorNegative - log P(-)\n",
        "#   returns (label of x according to the NB classification rule, confidence about the label)\n",
        "\n",
        "# Note: you can also change the function definition if you wish to encapsulate all six log probs\n",
        "# as one model; just make sure to follow through below\n",
        "\n",
        "def classifyNBOnlyAbsent(words,logProbWordAbsentGivenPositive,\n",
        "           logProbWordAbsentGivenNegative, logPriorPositive, logPriorNegative):\n",
        "\n",
        "  probTweetPositive = np.exp(logPriorPositive + np.sum(logProbWordAbsentGivenPositive[words==0]))\n",
        "  probTweetNegative = np.exp(logPriorNegative + np.sum(logProbWordAbsentGivenNegative[words==0]))\n",
        "\n",
        "  if probTweetPositive > probTweetNegative:\n",
        "    return 1, np.log(probTweetPositive / probTweetNegative)\n",
        "  else:\n",
        "    return -1, np.log(probTweetNegative / probTweetPositive)\n",
        "\n",
        "\n",
        "# testNBOnlyAbsent: Classify all xTest\n",
        "#   xTest - test data features\n",
        "#   yTest - true label of test data\n",
        "#   logProbWordAbsentGivenPositive  - log P(x_j = 0|+)\n",
        "#   logProbWordAbsentGivenNegative  - log P(x_j = 0|-)\n",
        "#   logPriorPositive - log P(+)\n",
        "#   logPriorNegative - log P(-)\n",
        "#   returns Average test error\n",
        "def testNBOnlyAbsent(xTest, yTest, logProbWordAbsentGivenPositive,\n",
        "           logProbWordAbsentGivenNegative, logPriorPositive, logPriorNegative):\n",
        "  totalError = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  numPos = 0\n",
        "  numNeg = 0\n",
        "\n",
        "  for i, words in enumerate(xTest):\n",
        "    classification, confidence = classifyNBOnlyAbsent(words,logProbWordAbsentGivenPositive,\n",
        "           logProbWordAbsentGivenNegative, logPriorPositive, logPriorNegative)\n",
        "\n",
        "    if classification != yTest[i]: totalError = totalError + 1\n",
        "    if classification == 1:\n",
        "      posConfidence += confidence\n",
        "      numPos += 1\n",
        "    else:\n",
        "      negConfidence += confidence\n",
        "      numNeg += 1\n",
        "\n",
        "  # compute accuracy and confidence\n",
        "  avgPosConfidence = posConfidence / numPos\n",
        "  avgNegConfidence = negConfidence / numNeg\n",
        "  accuracy = 1 - totalError/yTest.size\n",
        "\n",
        "  return accuracy, avgPosConfidence, avgNegConfidence\n",
        "\n",
        "# NtestNB: Run N iterations of testNB and gather average accuracy and confidence\n",
        "#   n - number of iterations\n",
        "#   X - occurance of words\n",
        "#   y - lables of data\n",
        "#   returns Average accuracy and confidence on positive and negative guesses for testNBOnlyAbsent over N iterations\n",
        "\n",
        "def NTestNBOnlyAbsent(n, X, y):\n",
        "  accuracy = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  for i in range(n):\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2)\n",
        "    # gets the prior probabilities and conditional probabilities from our training data\n",
        "    probWordGivenPositive, probWordGivenNegative, priorPositive, priorNegative = compute_distrobutions(xTrain,yTrain)\n",
        "    # converts probabilities to log form\n",
        "    min_prob = 1/yTrain.shape[0]\n",
        "    logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive = compute_log_probabilities(probWordGivenPositive, min_prob)\n",
        "    logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative = compute_log_probabilities(probWordGivenNegative, min_prob)\n",
        "    logPriorPositive, logPriorNegative = compute_log_probabilities(priorPositive, min_prob)\n",
        "\n",
        "    # performs test and sums accuracy/confidence\n",
        "    testAccuracy, testPosConfidence, testNegConfidence = testNBOnlyAbsent(xTest, yTest,\n",
        "           logProbWordAbsentGivenPositive, logProbWordAbsentGivenNegative, logPriorPositive, logPriorNegative)\n",
        "\n",
        "    accuracy += testAccuracy\n",
        "    posConfidence += testPosConfidence\n",
        "    negConfidence += testNegConfidence\n",
        "\n",
        "  avgAccuracy = accuracy / n\n",
        "  avgPosConfidence = posConfidence / n\n",
        "  avgNegConfidence = negConfidence / n\n",
        "  # print results of N tests\n",
        "  print(f\"--------------------NBOnlyAbsent--------------------\")\n",
        "  print(f\"Over {n} tests our NB was {avgAccuracy * 100}% accuracy on average\")\n",
        "  print(f\"Over {n} tests our NB scored {avgPosConfidence} confidence on positive guesses\")\n",
        "  print(f\"Over {n} tests our NB scored {avgNegConfidence} confidence on negative guesses\")\n",
        "  return avgAccuracy, avgPosConfidence, avgNegConfidence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Khjmiq7QPXS-"
      },
      "source": [
        "---\n",
        "---\n",
        "**Part 3: An Additional Experiment (50 pts)**\n",
        "\n",
        "Implement an experiment to change the model, and report on the results of the experiment, comparing to your baseline model from Part 1 (and your alternate model from Part 2).\n",
        "\n",
        "Choose one (and only one) of the following options.\n",
        "\n",
        "*Please make clear which option you choose! (For example, by deleting the options you are not choosing.)*\n",
        "\n",
        "**3.1: Option 1: Removing stop words**\n",
        "\n",
        "Investigate the effect of removing the 25, 50, 100, and 200 most frequent words from the calculation.\n",
        "\n",
        "**3.2: Option 2: Sample weights (3 bonus points for difficulty)**\n",
        "\n",
        "Recall that the labels for each of our data points/samples came with a weight. This weight was based on the proportion of labelers that agreed on this label, so it serves as a kind of measure of confidence we should have in each data point. That is, a weight near 1 indicates everyone agreed on the same label. Whereas a weight below 0.5 means not even a majority agreed on the chosen label.\n",
        "\n",
        "Devise a method for weighting samples, and use that method to recalculate the probability distributions.  Report the effect of weighting samples on the test set.\n",
        "\n",
        "(Hint: Re-examine part 1.6 and think about how you would change this to make it pay more attention to data points with higher weights.)\n",
        "\n",
        "**3.3: Option 3: Sticky terms (6 bonus points for difficulty)**\n",
        "\n",
        "A \"sticky term\" is two words which are more likely to occur together than independently.\n",
        "\n",
        "You can use \"Pointwise Mutual Information\" (PMI) to determine the stickiness, using: $PMI=\\frac{P(w_1,w_2)}{P(w_1)P(w_2)}$.  For all pairs of <u>adjacent</u> words in the tweet corpus, find the top n pairs according to PMI and add them as additional features in your Naive Bayes Model.\n",
        "\n",
        "Find the top 100, 200, 500 \"sticky terms\" and add these as features to the model.\n",
        "\n",
        "(Note, you cannot use X to calculate the above joint distribution, since the above is about adjacent words. You will have to go back to the raw text.)\n",
        "\n",
        "---\n",
        "\n",
        "Remember, you need to *compare* your chosen option with your previous work. Just writing the code is not sufficient. Follow reasonable experimental procedure and write up a discussion of your results and why you think they turned out that way."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sDHdimnqjYS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b83039-8595-4754-9f79-213d69034ced"
      },
      "source": [
        "# removeStopWords:\n",
        "#   numWords - vector of words of the tweet (binary vector)\n",
        "#   X - features to be split into train and test sets\n",
        "#   returns (label of x according to the NB classification rule, confidence about the label)\n",
        "\n",
        "# Note: you can also change the function definition if you wish to encapsulate all six log probs\n",
        "# as one model; just make sure to follow through below\n",
        "\n",
        "def removeStopWords(numWords, X):\n",
        "  sumWords = np.sum(X, axis=0)\n",
        "  sortedSumWords = np.sort(sumWords, kind=\"mergesort\")\n",
        "  cleanedX = X[:, sumWords < sortedSumWords[-numWords]]\n",
        "  return cleanedX\n",
        "\n",
        "# NtestNBRemoveStopWords: Run N iterations of testNB and gather average accuracy and confidence while removing stopwords\n",
        "#   n - number of iterations\n",
        "#   numWords - number of stop words to remove\n",
        "#   X - occurance of words\n",
        "#   y - lables of data\n",
        "#   returns Average accuracy and confidence on positive and negative guesses for testNB over N iterations with {numWords} most common words removed\n",
        "def NTestNBRemoveStopWords(n, numWords, X, y):\n",
        "  X = removeStopWords(numWords, X)\n",
        "  accuracy = 0\n",
        "  posConfidence = 0\n",
        "  negConfidence = 0\n",
        "  for i in range(n):\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2)\n",
        "    # gets the prior probabilities and conditional probabilities from our training data\n",
        "    probWordGivenPositive, probWordGivenNegative, priorPositive, priorNegative = compute_distrobutions(xTrain,yTrain)\n",
        "    # converts probabilities to log form\n",
        "    min_prob = 1/yTrain.shape[0]\n",
        "    logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive = compute_log_probabilities(probWordGivenPositive, min_prob)\n",
        "    logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative = compute_log_probabilities(probWordGivenNegative, min_prob)\n",
        "    logPriorPositive, logPriorNegative = compute_log_probabilities(priorPositive, min_prob)\n",
        "\n",
        "    # performs test and sums accuracy/confidence\n",
        "    testAccuracy, testPosConfidence, testNegConfidence = testNB(xTest, yTest,\n",
        "           logProbWordPresentGivenPositive, logProbWordAbsentGivenPositive,\n",
        "           logProbWordPresentGivenNegative, logProbWordAbsentGivenNegative,\n",
        "           logPriorPositive, logPriorNegative)\n",
        "\n",
        "    accuracy += testAccuracy\n",
        "    posConfidence += testPosConfidence\n",
        "    negConfidence += testNegConfidence\n",
        "\n",
        "  avgAccuracy = accuracy / n\n",
        "  avgPosConfidence = posConfidence / n\n",
        "  avgNegConfidence = negConfidence / n\n",
        "  # print results of N tests\n",
        "  print(f\"--------------------NBRemove{numWords}Words--------------------\")\n",
        "  print(f\"Over {n} tests our NB was {avgAccuracy * 100}% accuracy on average\")\n",
        "  print(f\"Over {n} tests our NB scored {avgPosConfidence} confidence on positive guesses\")\n",
        "  print(f\"Over {n} tests our NB scored {avgNegConfidence} confidence on negative guesses\")\n",
        "\n",
        "  return avgAccuracy, avgPosConfidence, avgNegConfidence\n",
        "\n",
        "# Calls to all our various Naive Bayes Classifers\n",
        "\n",
        "# Number of tests to run in each trial\n",
        "numberOfTests = 10\n",
        "\n",
        "# Baseline NB classifier\n",
        "NBavgAccuracy, NBavgPosConfidence, NBavgNegConfidence = NTestNB(numberOfTests, X, y)\n",
        "\n",
        "# NB classifier only considering present or absent words\n",
        "NBavgAccuracyOnlyPresent, NBavgPosConfidenceOnlyPresent, NBavgNegConfidenceOnlyPresent = NTestNBOnlyPresent(numberOfTests, X, y)\n",
        "NBavgAccuracyOnlyAbsent, NBavgPosConfidenceOnlyAbsent, NBavgNegConfidenceOnlyAbsent = NTestNBOnlyAbsent(numberOfTests, X, y)\n",
        "\n",
        "#NB classifier with 25, 50, 100, 200 stopwords removed\n",
        "NBavgAccuracyRemove25, NBavgPosConfidenceRemove25, NBavgNegConfidenceRemove25 = NTestNBRemoveStopWords(numberOfTests, 25, X, y)\n",
        "NBavgAccuracyRemove25, NBavgPosConfidenceRemove25, NBavgNegConfidenceRemove25 = NTestNBRemoveStopWords(numberOfTests, 50, X, y)\n",
        "NBavgAccuracyRemove25, NBavgPosConfidenceRemove25, NBavgNegConfidenceRemove25 = NTestNBRemoveStopWords(numberOfTests, 100, X, y)\n",
        "NBavgAccuracyRemove25, NBavgPosConfidenceRemove25, NBavgNegConfidenceRemove25 = NTestNBRemoveStopWords(numberOfTests, 200, X, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------NB--------------------\n",
            "Over 100 tests our NB was 82.89999999999999% accuracy on average\n",
            "Over 100 tests our NB scored 4.313647367811673 confidence on positive guesses\n",
            "Over 100 tests our NB scored 3.5914769042035193 confidence on negative guesses\n",
            "--------------------NBOnlyPresent--------------------\n",
            "Over 100 tests our NB was 82.70270270270271% accuracy on average\n",
            "Over 100 tests our NB scored 4.073734639229623 confidence on positive guesses\n",
            "Over 100 tests our NB scored 3.5369117147371436 confidence on negative guesses\n",
            "--------------------NBRemoveOnlyAbsent--------------------\n",
            "Over 100 tests our NB was 60.01621621621622% accuracy on average\n",
            "Over 100 tests our NB scored 0.45193207112944633 confidence on positive guesses\n",
            "Over 100 tests our NB scored 0.12793843819888595 confidence on negative guesses\n",
            "--------------------NBRemove25Words--------------------\n",
            "Over 100 tests our NB was 81.99189189189188% accuracy on average\n",
            "Over 100 tests our NB scored 3.7048214479143557 confidence on positive guesses\n",
            "Over 100 tests our NB scored 3.1594031474796322 confidence on negative guesses\n",
            "--------------------NBRemove50Words--------------------\n",
            "Over 100 tests our NB was 77.70675675675675% accuracy on average\n",
            "Over 100 tests our NB scored 3.1669593411352976 confidence on positive guesses\n",
            "Over 100 tests our NB scored 2.779270187687907 confidence on negative guesses\n",
            "--------------------NBRemove100Words--------------------\n",
            "Over 100 tests our NB was 74.26486486486488% accuracy on average\n",
            "Over 100 tests our NB scored 2.4650144201508684 confidence on positive guesses\n",
            "Over 100 tests our NB scored 2.397501335532257 confidence on negative guesses\n",
            "--------------------NBRemove200Words--------------------\n",
            "Over 100 tests our NB was 69.27567567567566% accuracy on average\n",
            "Over 100 tests our NB scored 1.8898126164807025 confidence on positive guesses\n",
            "Over 100 tests our NB scored 2.006227774188489 confidence on negative guesses\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}